{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cianhwang/physicsAwareTransformer/blob/master/PAT/Inference_as_a_whole_dual_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo notebook for \"Wide Field - Narrow Field System\"\n",
        "\n",
        "#### Qian Huang\n",
        "#### Feb 15, 2023\n",
        "\n",
        "CAUTION: this notebook is not fully tested on colab. Require 32G GPU RAM to run."
      ],
      "metadata": {
        "id": "yv_PsL2lHdze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### download required files\n",
        "\n",
        "! git clone https://github.com/djbradyAtOpticalSciencesArizona/physicsAwareTransformer.git\n",
        "! mv physicsAwareTransformer/PAT/* .\n",
        "! unzip data/061622_dual_vision_more_patches.zip"
      ],
      "metadata": {
        "id": "rpMNmerDbmWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### generate receptive field coordinates\n",
        "\n",
        "! python gen_dataset.py"
      ],
      "metadata": {
        "id": "pSXb_AF_dbyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5A5JQrlC5-A"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsXWK1SmC5-F"
      },
      "outputs": [],
      "source": [
        "from models import *\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "from utils import *\n",
        "import argparse\n",
        "import os\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4pPqQPMC5-F"
      },
      "outputs": [],
      "source": [
        "### load two source images.\n",
        "### allied_2.png: image from mono camera, 25mm fl\n",
        "### hr1.png: patch from color camera, 5mm fl\n",
        "\n",
        "path = './'\n",
        "img0 = Image.open(f'{path}/allied_2.png')\n",
        "img1 = Image.open(f'{path}/hr1.png')\n",
        "\n",
        "img0.size, img1.size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### split large image into 4 to save memory\n",
        "\n",
        "img0_0  = np.array(img0,  dtype=np.float32)[:1800, :2400, np.newaxis].repeat(3, axis=2)\n",
        "img0_1  = np.array(img0,  dtype=np.float32)[:1800, -2400:, np.newaxis].repeat(3, axis=2)\n",
        "img0_2  = np.array(img0,  dtype=np.float32)[-1800:, :2400, np.newaxis].repeat(3, axis=2)\n",
        "img0_3  = np.array(img0,  dtype=np.float32)[-1800:, -2400:, np.newaxis].repeat(3, axis=2)\n",
        "img1 = np.array(img1, dtype=np.float32)\n",
        "img_rights = [img1]"
      ],
      "metadata": {
        "id": "sfKIp4_ghBs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHAAK38qC5-H"
      },
      "outputs": [],
      "source": [
        "### convert numpy images to tensors\n",
        "\n",
        "def toTensor(img):\n",
        "    img = torch.from_numpy(img.transpose((2, 0, 1)))\n",
        "    return img.float().div(255)\n",
        "\n",
        "x_left0 = toTensor(img0_0).unsqueeze(0).to('cuda')\n",
        "x_left1 = toTensor(img0_1).unsqueeze(0).to('cuda')\n",
        "x_left2 = toTensor(img0_2).unsqueeze(0).to('cuda')\n",
        "x_left3 = toTensor(img0_3).unsqueeze(0).to('cuda')\n",
        "x_rights = [toTensor(img_right).unsqueeze(0).to('cuda') for img_right in img_rights]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlcWU-_sC5-H"
      },
      "outputs": [],
      "source": [
        "### load model\n",
        "\n",
        "net = PAT(1, in_channel=3, num_input=2).to('cuda')\n",
        "net = nn.DataParallel(net)\n",
        "net.eval()\n",
        "cudnn.benchmark = True\n",
        "pretrained_dict = torch.load('log_2inputs/x4/best.pth.tar')\n",
        "net.load_state_dict(pretrained_dict['state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGVuAbh6C5-J"
      },
      "outputs": [],
      "source": [
        "### compute initial features\n",
        "\n",
        "with torch.no_grad():\n",
        "    x_left0 = net.module.init_feature(x_left0)\n",
        "    x_left1 = net.module.init_feature(x_left1)\n",
        "    x_left2 = net.module.init_feature(x_left2)\n",
        "    x_left3 = net.module.init_feature(x_left3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_G-DV5vC5-J"
      },
      "outputs": [],
      "source": [
        "### combine splitted features\n",
        "\n",
        "x_up = torch.cat((x_left0[..., :2012], x_left1[..., -2012:]), dim=3)\n",
        "x_down = torch.cat((x_left2[..., :2012], x_left3[..., -2012:]), dim=3)\n",
        "x_left = torch.cat((x_up[:,:,:1518,:], x_down[:,:,-1518:,:]), dim=2).contiguous()\n",
        "x_left.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGg-zZx2C5-J"
      },
      "outputs": [],
      "source": [
        "### compute Q, K (Ss), V (Rs)\n",
        "\n",
        "with torch.no_grad():\n",
        "#     x_left = net.module.init_feature(x_left)\n",
        "    x_rights = [net.module.init_feature(x_right) for x_right in x_rights]\n",
        "    buffer_left = net.module.pam.rb(x_left)\n",
        "    buffer_rights = [net.module.pam.rb(x_right) for x_right in x_rights]\n",
        "    Q = net.module.pam.b1(buffer_left)\n",
        "    Ss, Rs = [], []\n",
        "    for i in range(len(buffer_rights)):\n",
        "        Ss.append(net.module.pam.b2s[i](buffer_rights[i]))\n",
        "        Rs.append(net.module.pam.b3s[i](buffer_rights[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akWB-9DrC5-L"
      },
      "outputs": [],
      "source": [
        "### compute output\n",
        "\n",
        "with torch.no_grad():\n",
        "    fused_feature = torch.zeros((1, 128, 3036, 4024)).float().to('cuda')\n",
        "    for i in range(132):\n",
        "        for j in range(8):\n",
        "            ID = i*8+j+1\n",
        "            print(ID)\n",
        "            xl, xu, yl, yu = i*23, i*23+23, j*503, j*503+503\n",
        "            \n",
        "            Q_ = Q[:, :, xl:xu,yl:yu].contiguous()\n",
        "            Pos = []\n",
        "\n",
        "            xxs = np.load('{}/xxs_{:04d}.npy'.format(path, ID))[np.newaxis]\n",
        "            yys = np.load('{}/yys_{:04d}.npy'.format(path, ID))[np.newaxis]\n",
        "            Pos.append((torch.from_numpy(xxs), torch.from_numpy(yys)))\n",
        "\n",
        "            buffers = []\n",
        "            for S, R, Po in zip(Ss, Rs, Pos):\n",
        "#                 print(Q_.size(), S.size(), R.size(), Po[0].size())\n",
        "                buffer, _ = net.module.pam.fe_pam(Q_, S, R, Po, False)\n",
        "                buffers.append(buffer)\n",
        "            buffers.append(x_left[:,:,xl:xu,yl:yu])\n",
        "            fused_feature[:,:,xl:xu,yl:yu] = torch.cat(tuple(buffers), 1)\n",
        "    out = net.module.pam.fusion(fused_feature)\n",
        "    out = net.module.upscale(out)  ### may cause OOM. If so, comment this line and run following block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItkA3lqpC5-M"
      },
      "outputs": [],
      "source": [
        "### workaround if OOM:\n",
        "### clear memory and load saved weights\n",
        "\n",
        "# torch.save(out, 'out.pt')\n",
        "# out = torch.load('out.pt').cuda()\n",
        "# with torch.no_grad():\n",
        "#     out = net.module.upscale(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIp9qxzSC5-O"
      },
      "outputs": [],
      "source": [
        "img = torch.clamp(out, 0, 1).squeeze().cpu().numpy().transpose(1, 2, 0)\n",
        "plt.figure(figsize=(20,16))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2p7q7GdC5-P"
      },
      "outputs": [],
      "source": [
        "cv2.imwrite(f'results/061622_dual_vision_more_patches_asawhole_x4.png', img[..., ::-1]*255.0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}